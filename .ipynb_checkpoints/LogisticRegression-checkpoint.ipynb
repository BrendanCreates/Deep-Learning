{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abff4891",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: otter-grader in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (6.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (8.2.1)\n",
      "Requirement already satisfied: dill>=0.3.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (0.4.0)\n",
      "Requirement already satisfied: fica>=0.4.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (0.4.1)\n",
      "Requirement already satisfied: ipylab<2.0.0,>=1.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (1.1.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (8.26.0)\n",
      "Requirement already satisfied: ipywidgets<9.0.0,>=8.1.5 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (8.1.7)\n",
      "Requirement already satisfied: jinja2<4.0,>=3.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (3.1.6)\n",
      "Requirement already satisfied: jupytext<2.0.0,>=1.16.4 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (1.17.3)\n",
      "Requirement already satisfied: nbconvert>=6.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (5.10.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (2.3.2)\n",
      "Requirement already satisfied: python-on-whales<1.0.0,>=0.72.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (0.78.0)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.16.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from otter-grader) (1.17.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click<9.0.0,>=8.1.7->otter-grader) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (0.2.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2<4.0,>=3.1->otter-grader) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (4.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (0.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (25.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-on-whales<1.0.0,>=0.72.0->otter-grader) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.31->otter-grader) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.31->otter-grader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.31->otter-grader) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3.0,>=2.31->otter-grader) (2025.8.3)\n",
      "Requirement already satisfied: docutils in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from fica>=0.4.1->otter-grader) (0.21.2)\n",
      "Requirement already satisfied: sphinx in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from fica>=0.4.1->otter-grader) (8.2.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython->otter-grader) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (311)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (8.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (27.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.5.2)\n",
      "Requirement already satisfied: playwright in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.55.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbformat>=5.0.0->otter-grader) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbformat>=5.0.0->otter-grader) (4.25.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=2.0.0->otter-grader) (2.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (2.8)\n",
      "Requirement already satisfied: pyee<14,>=13 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (3.2.4)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.1.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.0.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (3.0.1)\n",
      "Requirement already satisfied: babel>=2.13 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (2.17.0)\n",
      "Requirement already satisfied: alabaster>=0.7.14 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.0.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: roman-numerals-py>=1.0.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sphinx->fica>=0.4.1->otter-grader) (3.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->ipython->otter-grader) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->ipython->otter-grader) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\bnevi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\bnevi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install otter-grader\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add0ff4-27fa-4b8b-9429-77a6e70eb204",
   "metadata": {},
   "source": [
    "# FILL IN YOUR NAME AND THE NAME OF YOUR PEER (IF ANY) BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b0f41-932d-43fb-96b0-a10ea759b6e4",
   "metadata": {},
   "source": [
    "**Name**: Brendan Nevils\n",
    "\n",
    "**Peer**: \\<replace this with your peer's name\\>\n",
    "\n",
    "## Collaboration policy\n",
    "Students are responsible for writing their own quizzes, assignments, and exams. For homework assignments, students are welcome (and encouraged) to discuss problems with one peer, **but each student must write their own assignment writeup and code individually**. The peer must be listed at the top of the writeup for each assignment. *Note: I will treat AI assistants as peers. That is, students are welcome to discuss problems with an AI assistant, but it is considered cheating to directly obtain an answer by querying the assistant. Please credit any AI assistant that you use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99ca860-333f-401d-839f-4a9081aa36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before starting\n",
    "import numpy as np\n",
    "import inspect\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeaa842-e2ff-4f0d-9447-6450943e8703",
   "metadata": {},
   "source": [
    "# Homework 3 -- Logistic Regression (100 pts)\n",
    "\n",
    "**Due:** Wednesday, September 17th, 2025 at 11:59 pm\n",
    "\n",
    "For this homework, it will be helpful to review the slides and your notes on Logistic Regression.\n",
    "\n",
    "We will use Jupyter/Colab notebooks throughout the semester for writing code and generating assignment outputs. \n",
    "\n",
    "Note that some questions have public tests, and others do not. These are only intended to provide insight into what may not be working in your solution, but they generally do not count toward your grade. Passing all public tests does not guarantee that you will obtain full marks for a problem. The per-question score given to you by Gradescope is the only feedback you will obtain about your grade. It is possible that `print` statements may cause your code to receive no marks for a given question, so I encourage you to remove/comment out any `print` statements before submitting your assignment. **If you pass public tests but fail to obtain full marks on Gradescope, it is your responsibility to debug your code further (e.g., by devising additional test cases).**\n",
    "\n",
    "\n",
    "## 1) Linear Separability (10 pts)\n",
    "\n",
    "Below we plot three datasets. The $x_1$ and $x_2$ axes are the features available for training. Data points marked with black triangles are labeled as \"1\"; data points marked with white squares are labeled as \"-1\". We want to train a model that can predict the class given the features.\n",
    "\n",
    "<img src=\"https://introml.mit.edu/_static/spring24/questions/hypothesis_class/linearclass1.png\" width=\"100%\"/>\n",
    "\n",
    "### 1.1) \n",
    "Which of these datasets are linearly separable? For those that are linearly separable, choose any vector $\\theta$ and scalar $\\theta_0$ (written as $[[\\theta_1, \\theta_2]], \\theta_0]$) such that the classifier defined by $\\theta^\\top x + \\theta_0 > 0$ classifies every point correctly. For those that are not separable, choose \"not separable\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794950c-55b9-41e5-a0fb-6e4a2cd10ca2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.1)\n",
    "\n",
    "A:\n",
    "\n",
    "a) [[2, 1], 0]\n",
    "\n",
    "b) [[1, 2], 4]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0888281-ada9-4e65-9d3a-70e3be6efe8a",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_111 = \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c2f47-6bb2-4aff-878b-08977a887011",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.2)\n",
    "\n",
    "B:\n",
    "\n",
    "a) [[1, 0], 0]\n",
    "\n",
    "b) [[0, 1], 0]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b85dbc9-4feb-4af6-b433-56591c5ab2e8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_112 = \"c\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce3aca-180d-4f86-9064-8fc0832a2f7c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.1.3)\n",
    "\n",
    "C:\n",
    "\n",
    "a) [[1, 0], 0]\n",
    "\n",
    "b) [[0, 1], 0]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be736d5-2983-42d1-9db6-8958a68221a9",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_113 = \"c\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e0190-5ce1-4620-aafd-45881e804c6e",
   "metadata": {},
   "source": [
    "### 1.2)\n",
    "\n",
    "The plots from the previous question had omitted one of the features available in the raw data. Below we plot all three features (in a 3D plot). Given that 3D plots shown in 2D can be confusing, each column plots the same dataset viewed from different angles.\n",
    "\n",
    "<img src=\"https://introml.mit.edu/_static/spring24/questions/hypothesis_class/linearclass2.png\" width=\"100%\"/>\n",
    "\n",
    "Given this new third feature, which of the datasets are linearly separable? For those that are, choose the vector $\\theta$ and scalar $\\theta_0$ (written as $[[\\theta_1, \\theta_2, \\theta_3], \\theta_0]$) defining the classifier $\\theta^\\top x + \\theta_0$. For those that are not separable, choose \"not separable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefad285-4df2-45d4-83d2-90e0fda6ae41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.1)\n",
    "\n",
    "A:\n",
    "\n",
    "a) [[1, 2, 0], 0]\n",
    "\n",
    "b) [[1, 2, 0], 4]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cfd1fd8-1546-4a29-8ae7-a5e74e019dfd",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_121 = \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553bc5c-3d64-4a4f-ae0f-7fd5ed38948d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.2\n",
    "\n",
    "B:\n",
    "\n",
    "a) [[1, 0, 0], 0]\n",
    "\n",
    "b) [[0, 1, 0], 0]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d8857e-ebcf-4830-9137-d698776934b9",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_122 = \"c\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bb3bf-7a62-4e56-89c8-00fa127c9708",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.2.3)\n",
    "\n",
    "C:\n",
    "\n",
    "a) [[0, 1, 0], 0]\n",
    "\n",
    "b) [[0, 0, 1], 0]\n",
    "\n",
    "c) not separable\n",
    "\n",
    "_Points:_ 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de7a6e28-5992-484c-b98c-36699178e205",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_123 = \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03350ecc-ba47-4043-8da0-b570c5e33f3b",
   "metadata": {},
   "source": [
    "## 2) Simple linear logistic regression (10 pts)\n",
    "\n",
    "We are interested in linear logistic regression for input vectors representing points in $\\mathbb{R}^d$. We find a hypothesis of the form $$y=\\sigma(\\theta^\\top x + \\theta_0)\\enspace,$$ and, from it, derive a separator. Reminder: $\\sigma(0) = 0.5.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a5b91-e5e6-411a-a9af-f76203168528",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.1)\n",
    "\n",
    "What is the form of the **separator**?\n",
    "\n",
    "a) A $d$-dimensional hyperplane\n",
    "\n",
    "b) A $d+1$-dimensional hyperplane\n",
    "\n",
    "c) A $d-1$-dimensional hyperplane\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4131ff9-4ae3-473b-8575-e39bde7de2ed",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_21 = \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095cc53-1c7d-4939-a69c-ae6445a522c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2)\n",
    "\n",
    "If $d=1$, what is the separator?\n",
    "\n",
    "a) A point\n",
    "\n",
    "b) A line\n",
    "\n",
    "c) A plane\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b11fe66-fd4b-4996-a9ab-798f51059a87",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), and ans = \"c\" for (c)\n",
    "ans_22 = \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815370c-f909-4982-ac1b-da0ec174b9b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.3)\n",
    "\n",
    "For $d=1$, what is the equation of the separator? Provide a Python expression in terms of `theta` and `theta_0`. That is, we are looking for an expression of $x$ in terms of `theta` and `theta_0` such that $\\sigma(\\theta x+\\theta_0) = 0.5$. For simplicity, assume that both `theta` and `theta_0` are scalars, and return a scalar value.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4a8c96c-7266-48a9-b872-e5e4aba15314",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def separator_23(theta, theta_0):\n",
    "     return 0.5/theta - theta_0/theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "735a080c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tests directory does not exist and no notebook path provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq2.3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\otter\\check\\utils.py:242\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     ret \u001b[38;5;241m=\u001b[39m LoggedEventReturnValue(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\otter\\check\\utils.py:238\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03mRuns a method, catching any errors and logging the call. Returns the unwrapped return value\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03mof the wrapped function.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     ret: Optional[LoggedEventReturnValue[T]] \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\otter\\check\\notebook.py:256\u001b[0m, in \u001b[0;36mNotebook.check\u001b[1;34m(self, question, global_env)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mRuns tests for a specific question against a global environment. If no global environment\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03mis provided, the test is run against the calling frame's environment.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    ``otter.test_files.abstract_test.TestFile``: the grade for the question\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning check for question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 256\u001b[0m test_path, test_name \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_test_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tests_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_notebook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tests_url_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolved test path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolved test name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\otter\\check\\utils.py:351\u001b[0m, in \u001b[0;36mresolve_test_info\u001b[1;34m(tests_dir, nb_path, tests_url_prefix, question)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nb_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTests directory does not exist and no notebook path provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m     test_path \u001b[38;5;241m=\u001b[39m nb_path\n\u001b[0;32m    354\u001b[0m     test_name \u001b[38;5;241m=\u001b[39m question\n",
      "\u001b[1;31mValueError\u001b[0m: Tests directory does not exist and no notebook path provided"
     ]
    }
   ],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b6b4e-1aab-41d5-9b0f-d805a6d66e07",
   "metadata": {},
   "source": [
    "### 2.4)\n",
    "\n",
    "Here is a dataset in 1D of the form $\\{x^{(i)}, y^{(i)}\\}$: $$\\{(1, 1), (2, 1), (4, 0), (5, 0)\\}\\enspace.$$ (It might be helpful to draw out these data points for this problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5bedc-1ee9-492d-b04f-01a9b98e3f6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.4.1)\n",
    "Statment: the dataset is linearly separable. True or False?\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7a7e3-de8a-46a6-a236-1726f6ac81c7",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = True if the statement is true, and ans = False if it is false\n",
    "ans_241 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68790f-a47b-40d1-b01c-17f00a28ada2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.4.2)\n",
    "\n",
    "Intuitively, it seems like $x=3$ might be a good separator for this dataset, because it is a separator and it maximizes the distance to the closest points. Provide two different pairs of values $(\\theta, \\theta_0)$, such that in both cases, $\\sigma(\\theta x+\\theta_0)$ models the desired linear separator at $x=3$, and **correctly classifies** the dataset (i.e., a positive-labeled data point is classified as positive, and vise-versa). Enter your answer as a list of two lists, where each (sub)list is a $[\\theta, \\theta_0]$ pair.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a2155-594d-4fe8-b72b-e38f09efa3c2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_242 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2321b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11981267-1ce3-4333-8e8f-e77cc6c02bdc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.4.3)\n",
    "\n",
    "Statment: these parameters are optimal according to $\\mathcal{L}_{\\text{nll}}$. True or false?\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe7edb-597a-43f7-a3e4-bf7adb1941f0",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = True if the statement is true, and ans = False if it is false\n",
    "ans_243 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5055e34-66a6-416d-b347-6524865d5d28",
   "metadata": {},
   "source": [
    "### 2.5)\n",
    "\n",
    "Recall that in linear logistic regression $h(x; \\theta, \\theta_0)=\\sigma(\\theta^\\top x+\\theta_0)$. Consider the following transformations on $\\theta, \\theta_0$:\n",
    "\n",
    "**(A)** Multiply all parameters by 2\\\n",
    "**(B)** Multiply only $\\theta_0$ by 2\\\n",
    "**(C)** Multiply only $\\theta$ by 2\\\n",
    "**(D)** Multiply all parameters by -2\\\n",
    "**(E)** Add 1 to $\\theta_0$\\\n",
    "**(F)** Subtract 1 from $\\theta_0$\\\n",
    "**(G)** None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d1f446-d751-42a1-ac1f-417fdf1a1e69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.5.1)\n",
    "\n",
    "Suppose that $\\theta$ and $\\theta_0$ are non-zero. What transformation on $\\theta, \\theta_0$ makes the $h(x; \\theta, \\theta_0)$ function steeper but does not change which points $x\\in \\mathbb{R}^d$ are classified as 0 and which points are classified 1?\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612941e-9660-45e6-ac58-fdd339e57605",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), ans = \"c\" for (c)...\n",
    "ans_251 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a5c06-e554-468e-9b72-9d66b9bee40c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.5.2) \n",
    "\n",
    "Consider the case where $d=2$. What transformation on $\\theta,\\theta_0$ moves the separator to the left but does not change the steepness of $h(x; \\theta, \\theta_0)$? (If you have trouble thinking about this, you may find it helpful to take a look at [this Desmos](https://www.desmos.com/calculator/wljucrbpnq) demo for 1D intuition.)\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d6cf5-5824-4251-8bb9-754730047eec",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), ans = \"c\" for (c)...\n",
    "ans_252 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e398b3-ddb6-4586-824b-abd51096d4d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 2.5.3)\n",
    "\n",
    "If the separator classifies all points correctly, what transformation on $\\theta,\\theta_0$ would decrease $\\mathcal{L}_{\\text{nll}}$?\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f629275-c601-4a50-a852-0e90e26578a3",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# set ans = \"a\" for (a), ans = \"b\" for (b), ans = \"c\" for (c)...\n",
    "ans_253 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9111cf5-89b9-4457-8dec-cb76b18820a2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.6)\n",
    "\n",
    "Consider a hypothesis $h(x)=\\sigma(\\theta x +\\theta_0)$ in 1D. You want to move the separator in the positive direction by 1 while keeping the slope of the sigmoid the same. What are the updated values of the parameters you would use? \n",
    "\n",
    "Your function should take as input `theta` and `theta_0`, both scalar values, and return a tuple `(theta_new, theta_0_new)`, also both scalar values. \n",
    "\n",
    "**Hint**: You may find question 2.3 helpful for this question.\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deca450-cdc0-4242-8e69-fb1d604f2ac2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def parameters_26(theta, theta_0):\n",
    "    theta_new = ...\n",
    "    theta_0_new = ...\n",
    "    return theta_new, theta_0_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bf5be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da76ff-2275-479e-87b1-93e1c6b4b059",
   "metadata": {},
   "source": [
    "## 3) Why not linear regression? (20 pts)\n",
    "\n",
    "We went to all this trouble to make a new loss function for classification. Was it necessary?\n",
    "\n",
    "Here is another dataset in 1D of the form $\\{(x^{(i)}, y^{(i)}\\}$: $$\\{(1, 0), (2, 0), (3, 1), (100, 1)\\}\\enspace.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9685a-f34c-424d-a5bc-a01e562df708",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.1)\n",
    "\n",
    "Select all of the following that are true about logistic regression on this dataset:\n",
    "\n",
    "a) It will find a classifier with accuracy 1.0\\\n",
    "b) The optimal parameters, if not regularized, are finite\\\n",
    "c) The separator will be between 2 and 3\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6447120-d4b0-47a8-9ace-94ec0d93d5bc",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set ans to be a list containing strings representing each item above that is true \n",
    "# (e.g., [\"a\", \"b\", \"c\"] if all statements are true, or [] if no statement is true)\n",
    "ans_31 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc00ed-0b66-4d8a-84cd-0ffa5491f26f",
   "metadata": {},
   "source": [
    "### 3.2) \n",
    "\n",
    "We already know how to do linear regression. What if we treat this as a linear regression problem, with target $y$ values of 0 and 1, and the objective of minimizing mean squared loss (instead of NLL)? We ran OLS regression on this data and got $\\theta=0.007$ and $\\theta_0=0.316$ with mean squared error (MSE) $0.163$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b26aa3-ef83-4745-ba23-dee2da4e75f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.1) \n",
    "What scalar value represents the separator (at $y=0.5$) corresponding to this hypothesis? That is, at what $x$ value would our hypothesis predict a $y$ value of 0.5?\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aafa39-3413-479c-adae-2b4b258d9a84",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_321 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287cff9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e39402-9ad8-4120-a107-3c8c3dcf01be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.2)\n",
    "\n",
    "If we predict 1 when the line $y$ value is above 0.5 and predict 0 otherwise, how many points, out of four, do we predict correctly?\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b188e-76aa-4249-a036-035c53016566",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_322 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc9424",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea454856-b468-4cb7-849e-2ac438d7bd80",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.3)\n",
    "\n",
    "Select all of the following that are true:\n",
    "\n",
    "a) Logistic regression is able to accurately classify this data because the data are linearly separable\\\n",
    "b) Linear regression has trouble classifying this data accurately because the distant point has a large influence on the hypothesis\\\n",
    "c) Logistic regression doesn't work well on this data because the distant point is ignored\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6981e7a-967c-4850-bbf2-579bbcf4ac06",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Set ans to be a list containing strings representing each item above that is true \n",
    "# (e.g., [\"a\", \"b\", \"c\"] if all statements are true, or [] if no statement is true)\n",
    "ans_33 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae2939-b658-47fd-a622-35fb06a8be94",
   "metadata": {},
   "source": [
    "## 4) Deriving me crazy (20 pts)\n",
    "\n",
    "Our eventual goal is to do gradient descent on the logistic regression objective $J_{\\text{nll}}$.\n",
    "\n",
    "In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\\theta$ and $\\theta_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8b0da-435b-42e6-b41b-9ca51a837b66",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.1)\n",
    "\n",
    "What is an expression for the derivative of the sigmoid function $\\sigma(z) = \\frac{1}{1+e^{-z}}$ with respect to $z$, as a function of $z$, its input? Enter a Python expression, using `**` for exponentiation, `np.e` for Euler's constant $e$, and `z` for $z$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848ce9a-59fb-4499-82d4-c7b78501e9fe",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def dsigmoid_dz_41(z):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ebaa7-c08d-4e1f-9d8e-4642311b4898",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.2)\n",
    "What is an expression for the derivative of the sigmoid with respect to $z$, but this time expressed as a function of $o=\\sigma(z)=\\frac{1}{1+e^-z}$? (It's beautifully simple!)\n",
    "\n",
    "**Hint:** Think about the expression $\\left(1 - \\frac{1}{1+e^{-z}}\\right)$. (Here is a [review](https://www.mathsisfun.com/calculus/derivatives-rules.html) of computing derivatives.)\n",
    "\n",
    "Enter a Python expression using `**` for exponentiation, involving only `o`. `np.e` and `z` are not allowed, and remember $o=\\sigma(z)$.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475e666-7338-4a8f-8758-8831268dde8a",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def dsigmoid_dz_42(o):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed1a64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c4d7a-a337-4c8a-a8f5-c5832fc1756d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.3)\n",
    "\n",
    "### 4.3.1)\n",
    "\n",
    "What is the maximum value of $\\frac{d\\sigma(z)}{d z}$? Enter your answer as a scalar value.\n",
    "\n",
    "_Points:_ 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027ae7a-0078-408e-b06a-66ff598ccc6f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_431 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4371f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109aab4f-0cc3-4ce1-9a7a-916691de8bb2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 4.3.2) \n",
    "\n",
    "$\\frac{d\\sigma(z)}{dz}$ has an unreachable lower bound (some value that is always less than the actual value of $\\frac{\\sigma(z)}{dz}$). What is the value of this lower bound?\n",
    "\n",
    "_Points:_ 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87689ce-4dde-46df-83ae-96686a1c75b4",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_432 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507b85a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfcef9-e53a-47db-9735-36e86482284d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.4)\n",
    "\n",
    "Given the output of the model $$g=\\sigma(\\theta^\\top x +\\theta_0) = \\frac{1}{1+e^{(-\\theta^\\top x + \\theta_0)}}\\enspace,$$ what is the gradient of $g$ with respect to $\\theta$? Enter a Python expression involving `g` (shape `(1,1)`) and `x` (shape `(d,1)`).\n",
    "\n",
    "**Hint:** Use the chain rule and the expression you found for the derivative of the sigmoid in part 4.2.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab7020-c166-4800-bf88-1f5505515922",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def grad_sigmoid_44(g, x):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b065721",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4de452-0af6-425c-8b3c-7d7e55368a2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.5)\n",
    "\n",
    "The loss $L_{\\text{nll}}(g, y)$ is defined as:\n",
    "$$L_{\\text{nll}} = -\\big (y \\log g + (1 - y) \\log(1 - g) \\big)\\enspace.$$\n",
    "\n",
    "What is the derivative of the loss with respect to $g$? Enter a Python expression involving `y` and `g`. Assume `y` and `g` are scalars and return a scalar.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23636b-8f17-4d34-812b-25bc21c00031",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def dloss_dg_45(g, y):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aef89d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5db137-eb15-4745-8c21-44a2a281cbbd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.6)\n",
    "\n",
    "What is the gradient of $L_{\\text{nll}}$ with respect to $\\theta$? Enter a python expression involving `x` ($d\\times 1$), `y` (scalar or $1\\times 1$), and `g` (scalar or $1 \\times 1$).\n",
    "\n",
    "**Hint:** Use the chain rule and your expression from 5.3.\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54beb13-af65-4c4d-8815-1e692b9d4f4a",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def grad_loss_46(x, y, g):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9f2fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb4a31-3f72-4665-9110-87942c9e7b48",
   "metadata": {},
   "source": [
    "## 5) Multi-class logistic regression (20 pts)\n",
    "\n",
    "Recall from our slides and lecture notes how we can make use of **softmax** function to handle multiple classes in classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d46915-c13f-4464-a3c6-7a97d892dfca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 5.1) \n",
    "Assume we are doing multi-class logistic regression with three possible categories. What probability distribution over the categories is represented by $z=\\begin{bmatrix}-1\\\\0\\\\1\\end{bmatrix}$, where $z$ is the vector of inputs to the softmax transformation?\n",
    "\n",
    "Enter a distribution as a list of three non-negative numbers adding up to 1 for the three categories. Your answers should be numeric (please enter numbers, and do not use the symbol `np.e`).\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a529b09-ecf0-4a3e-9a4b-e8f465e1ebd8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_51 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b70d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b7da3-459f-4787-9f30-713bea3f7482",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 5.2)\n",
    "\n",
    "If our output distribution is $g=\\begin{bmatrix}0.3\\\\0.5\\\\0.2\\end{bmatrix}$ and the labels $y=\\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}$, what is $L_{\\text{NLLM}}(g, y)$ on this one point? Enter an expression involving `np.log()` (for natural log) and constants:\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b17465-3f62-45a1-aa5f-a9dbb6162cb6",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_52 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950b401",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0bd2d7-d72f-4ab5-99d4-d8663c952009",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 5.2.1)\n",
    "\n",
    "Suppose we are doing multi-class logistic regression with input dimension $d=2$ and number of classes $K=3$. Let the parameter matrix be: \n",
    "$$\\theta=\\begin{bmatrix} 1 & -1 & -2\\\\-1 & 2 & 1\\end{bmatrix}\\enspace.$$\n",
    "Assume $\\theta_0=\\begin{bmatrix}0\\\\0\\\\0\\end{bmatrix}$, $x=\\begin{bmatrix}1\\\\1\\end{bmatrix}$, and the target output $y=\\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}$. These are numpied for your convenience below:\n",
    "\n",
    "```\n",
    "th = np.array([[1, -1, -2], [-1, 2, 1]])\n",
    "x = np.array([[1, 1]]).T\n",
    "y = np.array([[0, 1, 0]]).T\n",
    "```\n",
    "\n",
    "What is the predicted probability that $x$ is in class 1, before any gradient updates? (Assume we have classes 0, 1, and 2.)\n",
    "\n",
    "Enter a number to at least 3 decimal places.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32914a5d-4e49-45d4-9bd2-42b6af7c4bef",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_521 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed28ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce925bd-b315-4fda-beef-f50ea85926f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 5.2.2)\n",
    "To do gradient descent, we ned to know $\\nabla_\\theta \\mathcal{L}_{\\text{NLLM}}(g, y)$. We will postpone doing the derivation, but just to let you know, it has an awesome form:\n",
    "$$ \\nabla_\\theta \\mathcal{L}_{NLLM}(g, y) = x(g - y)^\\top\\enspace.$$\n",
    "(Check the dimensions yourself to be sure that it's sensible.)\n",
    "\n",
    "If you don't want to think about the whole matrix of partial derivatives at once, we can write the partial derivative with respect to a single component $(i, j)$ of the parameter matrix:\n",
    "$$\\frac{d}{d \\theta_{ij}} \\mathcal{L}_{\\text{NLLM}}(g,y) = x_i(g_j - y_j)\\enspace.$$\n",
    "\n",
    "For the example we have developed in this question, what is the numeric value of the matrix $\\nabla_\\theta\\mathcal{L}_{\\text{NLLM}} (g, y)$? Enter the matrix as a list of lists, one inner list for each row of the matrix. Please enter values with a precision of three decimal points.\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e824ba5-e258-47f2-af22-211383827996",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_522 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ef725",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7726b71-1ae9-4d8a-865d-83fd90e84b3a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 5.3)\n",
    "\n",
    "Using a step size of $\\eta=0.5$, what is $\\theta$ after one gradient update step?\n",
    "\n",
    "Enter the matrix as a list of lists, one inner list for each row of the matrix. Please enter values with at least precision of three decimal points:\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1078d-d05c-46c5-9873-3c6d3bfde50b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_53 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b237052",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e88fa-3806-4c07-bc0f-5e92d5bfb732",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 5.4)\n",
    "What is the predicted probability that $x$ is in class 1, given the new weight matrix (the offset $\\theta_0$ is kept the same and not updated)? Enter a scalar to at least 3 decimal places:\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d9b0f-b957-4cd7-a410-6137058bb136",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ans_54 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b1da3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f68c10-5229-4acd-88de-96e52e9413cf",
   "metadata": {},
   "source": [
    "## 6) Applying gradient descent to linear logistic classifier objective (20 pts)\n",
    "\n",
    "Last week we implemented gradient descent in the general cae, so now we will apply it to negative log-likelihood (NLL). Our goal in this section will be to derive and implement appropriate gradient calculations that we can use with `gd` for optimization of the linear logistic classification (LLC) objective. In the derivations below, we'll consider linear binary classifiers _with_ offset; i.e., our collection of parameters is $\\theta, \\theta_0$.\n",
    "\n",
    "Recall that NLL loss for binary classification is defined as:\n",
    "$$L_{\\text{nll}}(g, y) = -\\big (y \\log g + (1-y) \\log(1-g)\\big)\\enspace.$$\n",
    "\n",
    "The objective function for LLC (a.k.a. logistic regression), takes the mean of the NLL los over all points and introduces a regularization term to this equation to make sure that the magnitude of $\\theta$ stays small:\n",
    "$$J_{lr} = (\\theta, \\theta_0) = \\left[\\frac{1}{n}\\sum_{i=1}^n L_{\\text{nll}} (\\sigma(\\theta^\\top x^{(i)} + \\theta_0), y^{(i)})\\right] +\\lambda\\|\\theta\\|^2\\enspace.$$\n",
    "\n",
    "We're interested in applying our gradient descent procedure to this function in order to find the 'best' separator for our data, where 'best' is measured by the lowest possible LLC objective. For your convenience, I have included public test cases to the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bccc03-97c1-4af9-b6ea-cb6021cc1406",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 6.1) Calculating the LLC objective\n",
    "\n",
    "First, implement the sigmoid function and implement NLL loss over the data points and separator. Using the latter function, implement the LLC objective. Note that these functions should work for matrix/vector arguments, so that we can compute the objective for a whole dataset with one call.\n",
    "\n",
    "Note that we're going to let `X` represent the full set of features across all the data points and `y` represent the full set of labels across all the data points. So `X` is $n\\times d$, `y` is $n\\times 1$, `th` is $d\\times 1$, `th0` is $1 \\times 1$, `lam` is a scalar.\n",
    "\n",
    "**Hint:** Look at `np.exp`, `np.log`.\n",
    "\n",
    "In the test cases for this problem, we'll use the following `super_simple_separable` test dataset and `sep_e_separator` test separator. A couple of the test cases are also shown below.\n",
    "\n",
    "```\n",
    "def super_simple_separable():\n",
    "    X = np.array([[2, 5],\n",
    "                  [3, 2],\n",
    "                  [9, 6],\n",
    "                  [12, 5]])\n",
    "    y = np.array([[1, 0, 1, 0]]).T\n",
    "    return X, y\n",
    "\n",
    "sep_e_separator = np.array([[-0.40338351], [1.1849563]]), np.array([[-2.26910091]])\n",
    "```\n",
    "\n",
    "**Test case 1**\n",
    "```\n",
    "x_1, y_1 = super_simple_separable()\n",
    "th1, th1_0 = sep_e_separator\n",
    "ans = llc_obj(x_1, y_1, th1, th1_0, .1)\n",
    "```\n",
    "\n",
    "\n",
    "**Test case 2**\n",
    "```\n",
    "ans = llc_obj(x_1, y_1, th1, th1_0, 0.0)\n",
    "```\n",
    "\n",
    "**Note:** in this section, you will code many individual functions, each of which depends on previous ones. I **strongly recommend** that you test each of the components on your own to debug.\n",
    "\n",
    "**Please use np.sum to take the sum of a matrix if needed.**\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da7a30-0c44-418b-8e42-17753015953f",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# returns a vector of the same shape as z\n",
    "def sigmoid_61(z):\n",
    "    ...\n",
    "\n",
    "# X is n x d, y is n x 1, th is d x 1, th0 is 1 x 1\n",
    "\n",
    "# returns a (n, 1) array for the nll loss for each data point given th and th0\n",
    "def nll_loss_61(X, y, th, th0):\n",
    "    ...\n",
    "\n",
    "# X is n x d, y is n x 1, th is d x 1, th0 is 1 x 1, lam is a scalar\n",
    "\n",
    "# returns a (1, 1) array for the llc objective over the dataset\n",
    "def llc_obj_61(X, y, th, th0, lam):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf9644",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14c218-20f9-41ed-91a5-aac64925935e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 6.2)\n",
    "\n",
    "Define a function `llc_obj_grad_62` that returns the gradient of the LLC objective function with respect to $\\theta$ and $\\theta_0$ in a single column vector. The last component of the gradient vector should be the partial derivative with respect to $\\theta_0$. Look at `np.vstack` as a simple way of stacking two matrices/vectors vertically. I have broken it down into pieces that mimic the steps in the chain rule; this leads to code that is a bit inefficient but easier to write and debug. We can worry about efficiency later.\n",
    "\n",
    "Some test cases that may be of use are shown below (be sure to take your time to understand these test cases):\n",
    "\n",
    "**Inputs to Test Cases**\n",
    "```\n",
    "X1 = np.array([[1, 2, 3, 9, 10]]).T\n",
    "y1 = np.array([[1, 1, 1, 0, 0]]).T\n",
    "th1, th10 = np.array([[-0.31202807]]), np.array([[1.834     ]])\n",
    "X2 = np.array([[2, 3, 9, 12],\n",
    "               [5, 2, 6, 5]]).T\n",
    "y2 = np.array([[1, 0, 1, 0]]).T\n",
    "th2, th20=np.array([[ -3.,  15.]]).T, np.array([[ 2.]])\n",
    "```\n",
    "\n",
    "**d_sigmoid Tests**\n",
    "```\n",
    "Test Case 1:\n",
    "d_sigmoid(np.array([[ 71.]]))\n",
    "\n",
    "Test Case 2:\n",
    "d_sigmoid(np.array([[ -23.]]))\n",
    "\n",
    "Test Case 3:\n",
    "d_sigmoid(np.array([[ 71, -23.]]))\n",
    "```\n",
    "\n",
    "**d_nll_loss_th Tests**\n",
    "```\n",
    "Test Case 4:\n",
    "d_nll_loss_th(X2[0:1, :], y2[0:1, :], th2, th20)\n",
    "\n",
    "Test Case 5:\n",
    "d_nll_loss_th(X2, y2, th2, th20)\n",
    "```\n",
    "\n",
    "**d_nll_loss_th0 Tests**\n",
    "```\n",
    "Test Case 6:\n",
    "d_nll_loss_th0(X2[0:1, :], y2[0:1, :], th2, th20)\n",
    "\n",
    "Test Case 7:\n",
    "d_nll_loss_th0(X2, y2, th2, th20)\n",
    "```\n",
    "\n",
    "**d_llc_obj_th Tests**\n",
    "```\n",
    "Test Case 8:\n",
    "d_llc_obj_th(X2[0:1, :], y2[0:1, :], th2, th20, 0.01)\n",
    "\n",
    "Test Case 9:\n",
    "d_llc_obj_th(X2, y2, th2, th20, 0.01)\n",
    "```\n",
    "\n",
    "**d_llc_obj_th0 Tests**\n",
    "```\n",
    "Test Case 10:\n",
    "d_llc_obj_th0(X2[0:1, :], y2[0:1, :], th2, th20, 0.01)\n",
    "\n",
    "Test Case 11:\n",
    "d_llc_obj_th0(X2, y2, th2, th20, 0.01)\n",
    "```\n",
    "\n",
    "**llc_obj_grad Tests**\n",
    "```\n",
    "Test Case 12:\n",
    "llc_obj_grad(X2, y2, th2, th20, 0.01)\n",
    "\n",
    "Test Case 13:\n",
    "llc_obj_grad(X2[0:1, :], y2[0:1, :], th2, th20, 0.01)\n",
    "```\n",
    "\n",
    "In this section, you will code many individual functions, each of which depends on previous ones. I strongly recommend that you test each of the components on your own to debug.\n",
    "\n",
    "**Hint:** Make sure to fully simplify the gradients in your implementation. Recall your solution to 4.2 and feel free to use your function `sigmoid_61` from the previous question.\n",
    "\n",
    "If using `np.sum` or `np.mean`, the optional `keepdims` argument (see [documentation](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)) preserves the number of dimensions (axes) of the output matrix.\n",
    "\n",
    "\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528f16b-aa77-4121-975d-78a105891852",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# returns an array of the same shape as z for the gradient of sigmoid(z)\n",
    "def d_sigmoid_62(z):\n",
    "    ...\n",
    "\n",
    "# returns a (n, d) array for the gradient of nll_loss_61(X, y, th, th0) with respect to th for each data point\n",
    "def d_nll_loss_th_62(X, y, th, th0):\n",
    "    ...\n",
    "\n",
    "# returns a (n, 1) array for the gradient of nll_loss_61(X, y, th, th0) with respect to th0\n",
    "def d_nll_loss_th0_62(X, y, th, th0):\n",
    "    ...\n",
    "\n",
    "# returns a (d,1) array for the gradient of llc_obj_61(X, y, th, th0) with respect to th\n",
    "def d_llc_obj_th_62(X, y, th, th0, lam):\n",
    "    ...\n",
    "\n",
    "# returns a (1,1) array for the gradient of llc_obj_61(X, y, th, th0) with respect to th0\n",
    "def d_llc_obj_th0_62(X, y, th, th0, lam):\n",
    "    ...\n",
    "\n",
    "# returns a (d+1, 1) array for the full gradient as a single vector (which includes both th, th0)\n",
    "def llc_obj_grad_62(X, y, th, th0, lam):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8eea2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef3c83-d63a-42e1-bc92-2b504922f99e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 6.3)\n",
    "\n",
    "Putting it all together, use the functions you built earlier to write a gradient descent minimizer for the LLC objective. You can directly call the functions you've defined above. You will need to reuse `gd` the gradient descent function which you implemented in HW2; your function `llc_min` should return the values that `gd` does. We have provided you with a sequence of step sizes already below.\n",
    "- Initialize all the separator parameters $\\theta, \\theta_0$ to zero\n",
    "- Use the step size function provided below\n",
    "- Specify 100 iterations\n",
    "\n",
    "**Hint:** the `f` and `df` that we feed into `gd` can ony have a single column vector as parameters; however, to call the objective and gradient functions you've written, you need both `theta` and `theta_0`. Think of a way to pass both of them into new functions `f` and `df` and then unpack them to call the objective and gradient functions. Look back at the structure of what `llc_obj_grad_62` returns in the previous problem.\n",
    "\n",
    "Some test cases are shown below, where an additional separable test dataset has been specified.\n",
    "\n",
    "```\n",
    "def separable_medium():\n",
    "    X = np.array([[2, -1, 1, 1],\n",
    "                  [-2, 2, 2, -1]]).T\n",
    "    y = np.array([[1, 0, 1, 0]]).T\n",
    "    return X, y\n",
    "sep_m_separator = np.array([[ 2.69231855], [ 0.67624906]]), np.array([[-3.02402521]])\n",
    "```\n",
    "\n",
    "**Test Case 1:**\n",
    "```\n",
    "x_1, y_1 = super_simple_separable()\n",
    "ans = llc_min_63(x_1, y_1, 0.0001)\n",
    "```\n",
    "\n",
    "**Test Case 2:**\n",
    "```\n",
    "x_2, y_2 = separable_medium()\n",
    "ans = llc_min_63(x_2, y_2, 0.0001)\n",
    "```\n",
    "\n",
    "_Points:_ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712124b5-82f6-40fc-a3e3-5eed215a8a95",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def gd_63(f, df, x0, step_size_fn, num_steps):\n",
    "    # The same function as gd_51 in HW2\n",
    "\n",
    "def llc_min_63(data, labels, lam):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        data: nxd\n",
    "        labels: nx1\n",
    "        lam: scalar\n",
    "    Returns: \n",
    "        same output as gd\n",
    "    \"\"\"\n",
    "    def llc_min_step_size_fn(i):\n",
    "        return 2 / (i + 1) ** 0.5\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad83b71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd955f86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Fill out the answers to all questions and submit your file hw3.ipynb to the HW3 assignment on Gradescope. You are free to resubmit as many times as you wish. If the code below throws an error about not being able to generate a PDF, don't worry about it. Your notebook should still be okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06339fc4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5e144",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "otter": {
   "assignment_name": "hw3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
